\section{Results}
The total number of correct classifications on the 100 test items, $P_{C}$, was determined for each participant. To compare observed to chance level performance, the Wilcoxon signed-rank test was employed for the \textit{normal} and the \textit{fast-time} conditions, while a one-sample t-test could be used for the \textit{fast-amount} condition. \footnote{The Shapiro-Wilk test was used to check whether the small samples per condition were drawn from a normally distributed population \citep{yazici2007comparison}} The tests were performed one-tailed because only above chance level performance was of interest. As can be seen from the results of these tests, illustrated in Table X (insert Table), no group performed significantly above chance. Therefore, it would not be sensible to make any statistical between-group comparisons. However, although not significant, both the \textit{normal} and the \textit{fast-amount} groups show weak indications that learning may have occurred. Luckily, there are other measures that can provide additional information on this matter.
\begin{table}[h]
\centering
\begin{tabular}{l l l l }
\toprule
\textbf{Group} & \textbf{Chance Level Comparison} & \textbf{\textit{p}-value} \\
\midrule
  normal      & Wilcoxon Signed Rank test        & .068 \\
  fast-amount & One-sample \textit{t}-test       & .057 \\
  fast-time   & Wilcoxon Signed Rank test        & .237 \\      
\bottomrule
\end{tabular}
\caption{TODO}
\end{table}
The 100 test items consisted of 50 unique items which were all repeated once. Thus, participants could classify each unique item in one of four ways:
\begin{enumerate}
\item Correct-Correct (CC): classified correctly on both presentations
\item Correct-Erroneous (CE): classified correctly on the first presentation but incorrectly on the second
\item Erroneous-Correct (EC): classified incorrectly on the first presentation but correctly on the second
\item Erroneous-Erroneous (EE): misclassified on both presentations
\end{enumerate}
The sum of CC and EE denotes overall consistency. Importantly, ``when the status of the item is known, it is always classified correctly; when it is not known, a guess is made.'' \citep[p.~227]{reber1989implicit}. Using this simple model as a basis, \citeauthor{reber1989implicit} states that CE, EC, and EE should not be statistically distinguishable from each other, since they all reflect guesses. On the other hand, if EE is significantly greater than the average of CE and EC, it can be inferred that judgments were based on rules that are not representative of the grammar. Furthermore, if the participants actually implicitly learned a correct albeit partial representation of the grammar, CC should be significantly higher than each of the other three variables. Finally, if the difference between CE and EC or EC and CE is significant, it is indicative of forgetting or learning during the testing phase respectively (for an in-depth discussion see \citet{reber1989implicit}). For each group, Table XX shows the means for the four variables. Intuitively, the illustrated behavior of our participants seems representative of guessing behavior on all test items. Paired t-tests for the various combinations of these variables (all are distributed normally within each group) confirms this intuition. EC and CE do not show a significant difference. Thus, there is neither evidence for learning nor for forgetting during the testing phase. When comparing EE to the average of CE and EC, $t(9) \leq -4.216$ and $p < .01$ was obtained for all groups. Furthermore, CC was only significantly higher than EE in the \textit{normal} group ($t(9)=1.843$, $p=.049$) with the \textit{fast-amount} group showing a trend ($t(9)=1.758$, $p=.057$). Taken together, this implies that all participants based a considerable amount of their decisions on rules that were not part of the grammar. Only in the \textit{normal} group (and possibly in the \textit{fast-amount} group) were significantly more correct than incorrect rules applied. However, it must be noted that these differences are much smaller and thus much move vague than in the artificial grammar learning literature.
\begin{table}[h]
\centering
\begin{tabular}{lllllll}
\toprule
& \multicolumn{6}{c}{\textbf{Group}} \\
\cmidrule{2-7}
\textbf{Parameter} & \multicolumn{2}{l}{\textbf{normal}} & \multicolumn{2}{l}{\textbf{fast-amount}} & \multicolumn{2}{l}{\textbf{fast-time}} \\
\midrule
 	    & Mean                       & SD                              & Mean & SD  & Mean & SD \\
\cmidrule(lr{.75em}){2-3}\cmidrule(lr{.75em}){4-5}\cmidrule(lr{.75em}){6-7}
$P_{C}$      & 53.3                       & 5.8                             & 52.9 & 5.2 & 50.9 & 4.8 \\
CC	    & 37.6                       & 5.8                             & 41.6 & 5.7 & 35.4 & 7.4 \\
CE 	    & 16.2                       & 6.8                             & 12.4 & 4.1 & 14.8 & 2.4 \\
EC	    & 15.4                       & 3.9                             & 10.2 & 5.7 & 16.2 & 1.9 \\
EE	    & 30.8                       & 7.5                             & 35.8 & 7.7 & 33.6 & 8.2 \\
consistency & 68.4                       &                                 & 77.4 &     & 50.9 & \\
\bottomrule
\end{tabular}
\caption{TODO}
\end{table}
Lastly, we correlated the number of languages participants speak as well as their prior speed reading experience with their $P_C$-scores across groups. Slightly negative but non-significant correlations were obtained: $r=-.30$, $p=.11$ for the number of languages and $r=-.23$, $p=.22$ for the speed reading experience.